{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Coursework 1 - Individual Report</h1></center>\n",
    "<h2><center>Friday 13th December 2019</center></h2>\n",
    "\n",
    "<h3> CST4050 - Modelling, Regression and Machine-Learning</h3>\n",
    "<h3>Student ID - M00740541</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 1: Open the data provided on UniHub and get a summary of the data. Standardise your data if\n",
    "needed</h3>\n",
    "<p> The first step is to import the librarys required for the task and to read in the data file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /Users/EllenTaylor/Desktop/ML Coursework 1/synthetic-4.csv does not exist: '/Users/EllenTaylor/Desktop/ML Coursework 1/synthetic-4.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d07c19159a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmydata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/EllenTaylor/Desktop/ML Coursework 1/synthetic-4.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /Users/EllenTaylor/Desktop/ML Coursework 1/synthetic-4.csv does not exist: '/Users/EllenTaylor/Desktop/ML Coursework 1/synthetic-4.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from random import seed\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "mydata = pd.read_csv (r'/Users/EllenTaylor/Desktop/ML Coursework 1/synthetic-4.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The 2 steps below provide a summary of the data set.</p>\n",
    "<p> As can be seen, the data is not standardised. To ensure the test data isn't touched standardisation will be applied after k-fold cross validation. This ensures the test data is unseen.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mydata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1c5de0ab0f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mydata' is not defined"
     ]
    }
   ],
   "source": [
    "print(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The statement above identifies the number of rows and columns in the datset. The data contains 1000 rows (observations) and 31 variables.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 2: Use train-test, 10-fold cross validation or, much better, 10-fold cross validation + validation set.</h3>\n",
    "<p> The below step splits the data into 10 folds</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfolds = 10\n",
    "kf = KFold(n_splits = nfolds, shuffle = True, random_state=0)\n",
    "kf.get_n_splits(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 3: Train and tune your classifier.</h3>\n",
    "<p> The below steps uses K Nearest Neighbour to train and tune the classifier. The accuracy for the classifer is then checked using F Score.</p>\n",
    "<p>Additionally in this step, the train data is standardised</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(mydata):\n",
    "    x_train, x_test = mydata.loc[train_index].drop(['y'], axis=1), mydata.loc[test_index].drop(['y'], axis=1) \n",
    "    y_train, y_test = mydata.loc[train_index][[\"y\"]], mydata.loc[test_index][[\"y\"]]\n",
    "        \n",
    "    fscore_train_k = np.array([])\n",
    "    fscore_test_k = np.array([])\n",
    "\n",
    "\n",
    "    scaler = StandardScaler() \n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train) \n",
    "    x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The below provides an overview of one of the Train K Folds to show that the train data has been standardised and the standard deviation is the same across all attributes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>9.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>6.180242e-17</td>\n",
       "      <td>2.675021e-16</td>\n",
       "      <td>1.791777e-17</td>\n",
       "      <td>5.082354e-17</td>\n",
       "      <td>-1.868875e-17</td>\n",
       "      <td>8.946547e-17</td>\n",
       "      <td>1.500035e-16</td>\n",
       "      <td>2.171103e-17</td>\n",
       "      <td>-2.590520e-17</td>\n",
       "      <td>-2.444958e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.844204e-17</td>\n",
       "      <td>-4.815901e-16</td>\n",
       "      <td>3.624139e-17</td>\n",
       "      <td>-1.238515e-16</td>\n",
       "      <td>-3.207311e-17</td>\n",
       "      <td>3.318333e-17</td>\n",
       "      <td>-4.849516e-18</td>\n",
       "      <td>-2.827368e-16</td>\n",
       "      <td>9.005142e-18</td>\n",
       "      <td>-4.132497e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "      <td>1.000556e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-3.444493e+00</td>\n",
       "      <td>-2.870404e+00</td>\n",
       "      <td>-3.447009e+00</td>\n",
       "      <td>-4.529718e+00</td>\n",
       "      <td>-3.322121e+00</td>\n",
       "      <td>-3.034552e+00</td>\n",
       "      <td>-2.723916e+00</td>\n",
       "      <td>-3.202667e+00</td>\n",
       "      <td>-3.374126e+00</td>\n",
       "      <td>-2.961825e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.178763e+00</td>\n",
       "      <td>-3.306153e+00</td>\n",
       "      <td>-2.993486e+00</td>\n",
       "      <td>-3.621101e+00</td>\n",
       "      <td>-2.998818e+00</td>\n",
       "      <td>-3.126295e+00</td>\n",
       "      <td>-3.073631e+00</td>\n",
       "      <td>-2.948442e+00</td>\n",
       "      <td>-3.167711e+00</td>\n",
       "      <td>-2.625669e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-6.995410e-01</td>\n",
       "      <td>-6.792286e-01</td>\n",
       "      <td>-6.717287e-01</td>\n",
       "      <td>-6.943199e-01</td>\n",
       "      <td>-7.034000e-01</td>\n",
       "      <td>-6.624167e-01</td>\n",
       "      <td>-6.970762e-01</td>\n",
       "      <td>-6.609552e-01</td>\n",
       "      <td>-6.651992e-01</td>\n",
       "      <td>-6.772248e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.589815e-01</td>\n",
       "      <td>-7.016020e-01</td>\n",
       "      <td>-7.053077e-01</td>\n",
       "      <td>-6.555322e-01</td>\n",
       "      <td>-6.792466e-01</td>\n",
       "      <td>-6.847489e-01</td>\n",
       "      <td>-6.849091e-01</td>\n",
       "      <td>-6.633564e-01</td>\n",
       "      <td>-6.384952e-01</td>\n",
       "      <td>-6.594725e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-5.026679e-03</td>\n",
       "      <td>-4.798186e-03</td>\n",
       "      <td>-1.254354e-02</td>\n",
       "      <td>1.117791e-02</td>\n",
       "      <td>2.982626e-02</td>\n",
       "      <td>-4.857394e-02</td>\n",
       "      <td>5.750235e-03</td>\n",
       "      <td>-6.860382e-03</td>\n",
       "      <td>-3.307517e-03</td>\n",
       "      <td>-6.313367e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.809949e-02</td>\n",
       "      <td>2.225186e-02</td>\n",
       "      <td>3.932323e-02</td>\n",
       "      <td>4.448263e-02</td>\n",
       "      <td>1.935974e-02</td>\n",
       "      <td>-1.994844e-02</td>\n",
       "      <td>2.839280e-02</td>\n",
       "      <td>3.386265e-03</td>\n",
       "      <td>-4.569227e-02</td>\n",
       "      <td>7.426199e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.771675e-01</td>\n",
       "      <td>6.392111e-01</td>\n",
       "      <td>6.789661e-01</td>\n",
       "      <td>6.521115e-01</td>\n",
       "      <td>6.638758e-01</td>\n",
       "      <td>6.559018e-01</td>\n",
       "      <td>6.496716e-01</td>\n",
       "      <td>6.827410e-01</td>\n",
       "      <td>6.956767e-01</td>\n",
       "      <td>6.453289e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.803760e-01</td>\n",
       "      <td>6.878995e-01</td>\n",
       "      <td>6.430699e-01</td>\n",
       "      <td>6.989192e-01</td>\n",
       "      <td>7.120494e-01</td>\n",
       "      <td>6.640773e-01</td>\n",
       "      <td>6.610432e-01</td>\n",
       "      <td>7.021023e-01</td>\n",
       "      <td>6.767347e-01</td>\n",
       "      <td>7.046859e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.920076e+00</td>\n",
       "      <td>2.910959e+00</td>\n",
       "      <td>3.577923e+00</td>\n",
       "      <td>3.321272e+00</td>\n",
       "      <td>4.107128e+00</td>\n",
       "      <td>3.639517e+00</td>\n",
       "      <td>2.981926e+00</td>\n",
       "      <td>3.376415e+00</td>\n",
       "      <td>2.897959e+00</td>\n",
       "      <td>3.337897e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.482533e+00</td>\n",
       "      <td>2.918514e+00</td>\n",
       "      <td>3.077345e+00</td>\n",
       "      <td>3.107379e+00</td>\n",
       "      <td>3.313214e+00</td>\n",
       "      <td>2.936643e+00</td>\n",
       "      <td>3.260529e+00</td>\n",
       "      <td>2.985453e+00</td>\n",
       "      <td>2.885547e+00</td>\n",
       "      <td>3.803516e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  9.000000e+02  9.000000e+02  9.000000e+02  9.000000e+02  9.000000e+02   \n",
       "mean   6.180242e-17  2.675021e-16  1.791777e-17  5.082354e-17 -1.868875e-17   \n",
       "std    1.000556e+00  1.000556e+00  1.000556e+00  1.000556e+00  1.000556e+00   \n",
       "min   -3.444493e+00 -2.870404e+00 -3.447009e+00 -4.529718e+00 -3.322121e+00   \n",
       "25%   -6.995410e-01 -6.792286e-01 -6.717287e-01 -6.943199e-01 -7.034000e-01   \n",
       "50%   -5.026679e-03 -4.798186e-03 -1.254354e-02  1.117791e-02  2.982626e-02   \n",
       "75%    6.771675e-01  6.392111e-01  6.789661e-01  6.521115e-01  6.638758e-01   \n",
       "max    2.920076e+00  2.910959e+00  3.577923e+00  3.321272e+00  4.107128e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  9.000000e+02  9.000000e+02  9.000000e+02  9.000000e+02  9.000000e+02   \n",
       "mean   8.946547e-17  1.500035e-16  2.171103e-17 -2.590520e-17 -2.444958e-16   \n",
       "std    1.000556e+00  1.000556e+00  1.000556e+00  1.000556e+00  1.000556e+00   \n",
       "min   -3.034552e+00 -2.723916e+00 -3.202667e+00 -3.374126e+00 -2.961825e+00   \n",
       "25%   -6.624167e-01 -6.970762e-01 -6.609552e-01 -6.651992e-01 -6.772248e-01   \n",
       "50%   -4.857394e-02  5.750235e-03 -6.860382e-03 -3.307517e-03 -6.313367e-04   \n",
       "75%    6.559018e-01  6.496716e-01  6.827410e-01  6.956767e-01  6.453289e-01   \n",
       "max    3.639517e+00  2.981926e+00  3.376415e+00  2.897959e+00  3.337897e+00   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  9.000000e+02  9.000000e+02  9.000000e+02  9.000000e+02   \n",
       "mean   ...  1.844204e-17 -4.815901e-16  3.624139e-17 -1.238515e-16   \n",
       "std    ...  1.000556e+00  1.000556e+00  1.000556e+00  1.000556e+00   \n",
       "min    ... -3.178763e+00 -3.306153e+00 -2.993486e+00 -3.621101e+00   \n",
       "25%    ... -6.589815e-01 -7.016020e-01 -7.053077e-01 -6.555322e-01   \n",
       "50%    ...  1.809949e-02  2.225186e-02  3.932323e-02  4.448263e-02   \n",
       "75%    ...  6.803760e-01  6.878995e-01  6.430699e-01  6.989192e-01   \n",
       "max    ...  3.482533e+00  2.918514e+00  3.077345e+00  3.107379e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  9.000000e+02  9.000000e+02  9.000000e+02  9.000000e+02  9.000000e+02   \n",
       "mean  -3.207311e-17  3.318333e-17 -4.849516e-18 -2.827368e-16  9.005142e-18   \n",
       "std    1.000556e+00  1.000556e+00  1.000556e+00  1.000556e+00  1.000556e+00   \n",
       "min   -2.998818e+00 -3.126295e+00 -3.073631e+00 -2.948442e+00 -3.167711e+00   \n",
       "25%   -6.792466e-01 -6.847489e-01 -6.849091e-01 -6.633564e-01 -6.384952e-01   \n",
       "50%    1.935974e-02 -1.994844e-02  2.839280e-02  3.386265e-03 -4.569227e-02   \n",
       "75%    7.120494e-01  6.640773e-01  6.610432e-01  7.021023e-01  6.767347e-01   \n",
       "max    3.313214e+00  2.936643e+00  3.260529e+00  2.985453e+00  2.885547e+00   \n",
       "\n",
       "                 29  \n",
       "count  9.000000e+02  \n",
       "mean  -4.132497e-18  \n",
       "std    1.000556e+00  \n",
       "min   -2.625669e+00  \n",
       "25%   -6.594725e-01  \n",
       "50%    7.426199e-03  \n",
       "75%    7.046859e-01  \n",
       "max    3.803516e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The below provides an overview of Test K Folds to show that the test data has not been standardised and the standard deviation is different across all attributes</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-0.048990</td>\n",
       "      <td>-0.035197</td>\n",
       "      <td>-0.181722</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>-0.077184</td>\n",
       "      <td>-0.051211</td>\n",
       "      <td>-0.027043</td>\n",
       "      <td>-0.046933</td>\n",
       "      <td>0.133835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097555</td>\n",
       "      <td>-0.012376</td>\n",
       "      <td>0.112135</td>\n",
       "      <td>0.062928</td>\n",
       "      <td>-0.059227</td>\n",
       "      <td>0.123342</td>\n",
       "      <td>-0.003355</td>\n",
       "      <td>0.076777</td>\n",
       "      <td>-0.181600</td>\n",
       "      <td>-0.204253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.052977</td>\n",
       "      <td>0.963341</td>\n",
       "      <td>0.989980</td>\n",
       "      <td>1.001604</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>1.230920</td>\n",
       "      <td>1.035308</td>\n",
       "      <td>1.000407</td>\n",
       "      <td>0.888708</td>\n",
       "      <td>1.100496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.962957</td>\n",
       "      <td>0.921979</td>\n",
       "      <td>0.942787</td>\n",
       "      <td>0.993103</td>\n",
       "      <td>1.087677</td>\n",
       "      <td>0.891426</td>\n",
       "      <td>1.065932</td>\n",
       "      <td>0.972465</td>\n",
       "      <td>0.992415</td>\n",
       "      <td>1.058371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-3.037110</td>\n",
       "      <td>-2.153279</td>\n",
       "      <td>-3.138590</td>\n",
       "      <td>-2.032543</td>\n",
       "      <td>-2.770003</td>\n",
       "      <td>-4.729572</td>\n",
       "      <td>-2.545403</td>\n",
       "      <td>-2.129333</td>\n",
       "      <td>-2.202102</td>\n",
       "      <td>-2.530765</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.184734</td>\n",
       "      <td>-1.651312</td>\n",
       "      <td>-2.244542</td>\n",
       "      <td>-2.125344</td>\n",
       "      <td>-2.403901</td>\n",
       "      <td>-1.862744</td>\n",
       "      <td>-2.528961</td>\n",
       "      <td>-2.417704</td>\n",
       "      <td>-2.594131</td>\n",
       "      <td>-3.098451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.766428</td>\n",
       "      <td>-0.739951</td>\n",
       "      <td>-0.773692</td>\n",
       "      <td>-0.560963</td>\n",
       "      <td>-0.652264</td>\n",
       "      <td>-0.790700</td>\n",
       "      <td>-0.693575</td>\n",
       "      <td>-0.635064</td>\n",
       "      <td>-0.639426</td>\n",
       "      <td>-0.636648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817929</td>\n",
       "      <td>-0.753380</td>\n",
       "      <td>-0.494242</td>\n",
       "      <td>-0.755453</td>\n",
       "      <td>-0.849871</td>\n",
       "      <td>-0.450343</td>\n",
       "      <td>-0.701540</td>\n",
       "      <td>-0.547693</td>\n",
       "      <td>-0.879126</td>\n",
       "      <td>-0.822004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-0.125909</td>\n",
       "      <td>-0.056613</td>\n",
       "      <td>-0.220969</td>\n",
       "      <td>-0.110087</td>\n",
       "      <td>0.045777</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>-0.098350</td>\n",
       "      <td>-0.077487</td>\n",
       "      <td>-0.004797</td>\n",
       "      <td>0.252090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122407</td>\n",
       "      <td>-0.094833</td>\n",
       "      <td>-0.002789</td>\n",
       "      <td>0.108541</td>\n",
       "      <td>-0.122461</td>\n",
       "      <td>0.102596</td>\n",
       "      <td>0.069287</td>\n",
       "      <td>0.072488</td>\n",
       "      <td>-0.283520</td>\n",
       "      <td>-0.113371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.692940</td>\n",
       "      <td>0.583204</td>\n",
       "      <td>0.350697</td>\n",
       "      <td>0.788667</td>\n",
       "      <td>0.739543</td>\n",
       "      <td>0.682811</td>\n",
       "      <td>0.626613</td>\n",
       "      <td>0.624409</td>\n",
       "      <td>0.576122</td>\n",
       "      <td>0.882696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439585</td>\n",
       "      <td>0.617811</td>\n",
       "      <td>0.808687</td>\n",
       "      <td>0.826892</td>\n",
       "      <td>0.781478</td>\n",
       "      <td>0.687901</td>\n",
       "      <td>0.753619</td>\n",
       "      <td>0.726708</td>\n",
       "      <td>0.604995</td>\n",
       "      <td>0.461175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>2.653668</td>\n",
       "      <td>2.570047</td>\n",
       "      <td>1.852846</td>\n",
       "      <td>3.438509</td>\n",
       "      <td>2.190264</td>\n",
       "      <td>2.647930</td>\n",
       "      <td>2.930977</td>\n",
       "      <td>2.532246</td>\n",
       "      <td>1.721941</td>\n",
       "      <td>2.872635</td>\n",
       "      <td>...</td>\n",
       "      <td>2.210933</td>\n",
       "      <td>2.661311</td>\n",
       "      <td>2.229842</td>\n",
       "      <td>2.706817</td>\n",
       "      <td>2.234173</td>\n",
       "      <td>2.281540</td>\n",
       "      <td>2.456525</td>\n",
       "      <td>2.841630</td>\n",
       "      <td>2.007813</td>\n",
       "      <td>2.170023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean    -0.048990   -0.035197   -0.181722    0.038307    0.002386   -0.077184   \n",
       "std      1.052977    0.963341    0.989980    1.001604    0.998304    1.230920   \n",
       "min     -3.037110   -2.153279   -3.138590   -2.032543   -2.770003   -4.729572   \n",
       "25%     -0.766428   -0.739951   -0.773692   -0.560963   -0.652264   -0.790700   \n",
       "50%     -0.125909   -0.056613   -0.220969   -0.110087    0.045777    0.007772   \n",
       "75%      0.692940    0.583204    0.350697    0.788667    0.739543    0.682811   \n",
       "max      2.653668    2.570047    1.852846    3.438509    2.190264    2.647930   \n",
       "\n",
       "               6           7           8           9   ...          20  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  ...  100.000000   \n",
       "mean    -0.051211   -0.027043   -0.046933    0.133835  ...   -0.097555   \n",
       "std      1.035308    1.000407    0.888708    1.100496  ...    0.962957   \n",
       "min     -2.545403   -2.129333   -2.202102   -2.530765  ...   -2.184734   \n",
       "25%     -0.693575   -0.635064   -0.639426   -0.636648  ...   -0.817929   \n",
       "50%     -0.098350   -0.077487   -0.004797    0.252090  ...   -0.122407   \n",
       "75%      0.626613    0.624409    0.576122    0.882696  ...    0.439585   \n",
       "max      2.930977    2.532246    1.721941    2.872635  ...    2.210933   \n",
       "\n",
       "               21          22          23          24          25          26  \\\n",
       "count  100.000000  100.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean    -0.012376    0.112135    0.062928   -0.059227    0.123342   -0.003355   \n",
       "std      0.921979    0.942787    0.993103    1.087677    0.891426    1.065932   \n",
       "min     -1.651312   -2.244542   -2.125344   -2.403901   -1.862744   -2.528961   \n",
       "25%     -0.753380   -0.494242   -0.755453   -0.849871   -0.450343   -0.701540   \n",
       "50%     -0.094833   -0.002789    0.108541   -0.122461    0.102596    0.069287   \n",
       "75%      0.617811    0.808687    0.826892    0.781478    0.687901    0.753619   \n",
       "max      2.661311    2.229842    2.706817    2.234173    2.281540    2.456525   \n",
       "\n",
       "               27          28          29  \n",
       "count  100.000000  100.000000  100.000000  \n",
       "mean     0.076777   -0.181600   -0.204253  \n",
       "std      0.972465    0.992415    1.058371  \n",
       "min     -2.417704   -2.594131   -3.098451  \n",
       "25%     -0.547693   -0.879126   -0.822004  \n",
       "50%      0.072488   -0.283520   -0.113371  \n",
       "75%      0.726708    0.604995    0.461175  \n",
       "max      2.841630    2.007813    2.170023  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x_test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6>Training and Tuning using K Nearest Neighbour (KNN)</h6>\n",
    "<p>The KNN model was tunned, by selecting K values from: 0 to 100 and getting the\n",
    "F Score of 10-fold testing for each value of K.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kvalues = range(1,100) \n",
    "fscore_acc = []\n",
    "\n",
    "penalties = np.array([])\n",
    "f_scores_train = np.array([]) \n",
    "f_scores_test = np.array([])\n",
    "\n",
    "for k in kvalues:\n",
    "    for train_index, test_index in kf.split(mydata):\n",
    "\n",
    "        knn = KNeighborsClassifier(n_neighbors = k)\n",
    "        knn.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "        pred_train = knn.predict(x_train)\n",
    "        pred_test = knn.predict(x_test)\n",
    "        \n",
    "        fscore_train = f1_score(y_train, pred_train)\n",
    "        fscore_test = f1_score(y_test, pred_test)\n",
    "        \n",
    "        fscore_train_k = np.append(fscore_train_k,fscore_train)\n",
    "        fscore_test_k = np.append(fscore_test_k,fscore_test)\n",
    "     \n",
    "    penalties = np.append(penalties, k)\n",
    "    \n",
    "    f_scores_train=np.append(f_scores_train,fscore_train_k.mean())\n",
    "    f_scores_test=np.append(f_scores_test,fscore_test_k.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Task 4. Compute the accuracy of your tuned classifier and compare it to a baseline.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The below 2 steps shows the  F Score for Train and Test data to demonstrate the accuracy of the model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.67532468, 0.61161996, 0.49800068, 0.4555434 ,\n",
       "       0.39677637, 0.36207205, 0.31875103, 0.29001762, 0.26101586,\n",
       "       0.23868575, 0.22008726, 0.20435007, 0.18975364, 0.17915468,\n",
       "       0.16893408, 0.15991589, 0.15103168, 0.14308264, 0.13592851,\n",
       "       0.12945572, 0.12357137, 0.1181987 , 0.11327376, 0.10874281,\n",
       "       0.10456039, 0.10068779, 0.09709179, 0.0937438 , 0.09061901,\n",
       "       0.08769581, 0.08495532, 0.08238092, 0.07995795, 0.07767343,\n",
       "       0.07551584, 0.07347487, 0.07154132, 0.06970693, 0.06796426,\n",
       "       0.06630659, 0.06472786, 0.06322256, 0.06178569, 0.06041267,\n",
       "       0.05909935, 0.05784192, 0.05663688, 0.05548102, 0.0543714 ,\n",
       "       0.0533053 , 0.0522802 , 0.05129378, 0.05034389, 0.04942855,\n",
       "       0.0485459 , 0.04769421, 0.0468719 , 0.04607746, 0.0453095 ,\n",
       "       0.04456672, 0.04384791, 0.04315191, 0.04247766, 0.04182416,\n",
       "       0.04119046, 0.04057567, 0.03997897, 0.03939957, 0.03883672,\n",
       "       0.03828972, 0.03775792, 0.03724069, 0.03673744, 0.0362476 ,\n",
       "       0.03577066, 0.03530611, 0.03485346, 0.03441228, 0.03398213,\n",
       "       0.0335626 , 0.0331533 , 0.03275386, 0.03236393, 0.03198318,\n",
       "       0.03161128, 0.03124793, 0.03089284, 0.03054573, 0.03020634,\n",
       "       0.0298744 , 0.02954968, 0.02923194, 0.02892096, 0.02861653,\n",
       "       0.02831844, 0.0280265 , 0.02774051, 0.02746031])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_scores_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32432432, 0.25740026, 0.27416427, 0.231939  , 0.22364643,\n",
       "       0.20391589, 0.18982264, 0.16609481, 0.14763983, 0.13287585,\n",
       "       0.13897804, 0.13616847, 0.14107859, 0.14528726, 0.14893478,\n",
       "       0.1462053 , 0.14379694, 0.14165617, 0.13974075, 0.13801687,\n",
       "       0.13645717, 0.13503926, 0.13374465, 0.12817195, 0.12304508,\n",
       "       0.11831257, 0.11393063, 0.10986168, 0.10607334, 0.10253756,\n",
       "       0.0992299 , 0.09612897, 0.09321597, 0.09047432, 0.08788934,\n",
       "       0.08544797, 0.08313857, 0.08095071, 0.07887505, 0.07690317,\n",
       "       0.07502749, 0.07324112, 0.07153784, 0.06991198, 0.06835838,\n",
       "       0.06687232, 0.06544951, 0.06408598, 0.0627781 , 0.06152254,\n",
       "       0.06031621, 0.05915629, 0.05804013, 0.05696531, 0.05592958,\n",
       "       0.05493084, 0.05396714, 0.05303667, 0.05213774, 0.05126878,\n",
       "       0.05042831, 0.04961495, 0.04882741, 0.04806448, 0.04732503,\n",
       "       0.04660798, 0.04591234, 0.04523716, 0.04458155, 0.04394467,\n",
       "       0.04332573, 0.04272398, 0.04213872, 0.04156928, 0.04101503,\n",
       "       0.04047535, 0.0399497 , 0.03943752, 0.03893832, 0.03845159,\n",
       "       0.03797688, 0.03751374, 0.03706177, 0.03662056, 0.03618973,\n",
       "       0.03576892, 0.03535778, 0.03495599, 0.03456322, 0.03417919,\n",
       "       0.03380359, 0.03343616, 0.03307663, 0.03272475, 0.03238028,\n",
       "       0.03204299, 0.03171265, 0.03138905, 0.03107199])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_scores_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Each value of K value is plotted against F Score to show the K value which is maximising the test score</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(penalties, f_scores_train, 'm--', label='F Score Train') \n",
    "plt.plot(penalties, f_scores_test, 'm', label='F Score on Test') \n",
    "plt.xlabel(r'Coefficient K', fontsize=16)\n",
    "plt.ylabel('F Score Accuracy', fontsize=16) \n",
    "plt.legend(fontsize=13, loc=1)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The graph shows that the model initially overfits the data as the F Score is higher than in the test data. The F Score for train and test then fits better as the K Value increases</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The below shows the best K Value for the model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "tuned_K_value = kvalues[np.argmax(f_scores_test)]\n",
    "print(tuned_K_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Value: 1\n",
      "F Score on Train: 1.0\n",
      "F Score on Test: 0.32432432432432423\n"
     ]
    }
   ],
   "source": [
    "print(\"K Value:\", kvalues[np.argmax(f_scores_train)])\n",
    "print(\"F Score on Train:\", f_scores_train [np.argmax(f_scores_train)])\n",
    "print(\"F Score on Test:\",f_scores_test[np.argmax(f_scores_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h6> The below compares the KNN model to a baseline</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def zero_rule_algorithm_classification(x_train, x_test):\n",
    "    output_values = [row for row in x_train]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    predicted = [prediction for i in range(len(x_train))]\n",
    "    return predicted\n",
    "\n",
    "seed(1)\n",
    "predictions = zero_rule_algorithm_classification(mydata.y, x_test)\n",
    "print(max(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[855   0]\n",
      " [145   0]]\n",
      "Accuracy Score : 0.855\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       855\n",
      "           1       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.43      0.50      0.46      1000\n",
      "weighted avg       0.73      0.85      0.79      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "actual = [mydata.y]  \n",
    "results = confusion_matrix(mydata.y, predictions) \n",
    "print('Confusion Matrix :')\n",
    "print(results) \n",
    "print('Accuracy Score :',accuracy_score(mydata.y, predictions) )\n",
    "print('Report : ')\n",
    "print(classification_report(mydata.y, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
